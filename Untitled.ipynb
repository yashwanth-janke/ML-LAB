{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4311719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of x: 0.4999999998981482\n",
      "Iteration: 0 Cost: 0.61 Weight: 0.1\n",
      "Iteration: 1 Cost: 0.3123999999999999 Weight: 0.18000000000000002\n",
      "Iteration: 2 Cost: 0.08353600000000005 Weight: 0.244\n",
      "Iteration: 3 Cost: -0.09365696000000012 Weight: 0.2952\n",
      "Iteration: 4 Cost: -0.23163645440000002 Weight: 0.33616\n",
      "Iteration: 5 Cost: -0.33960413081600005 Weight: 0.36892800000000003\n",
      "Iteration: 6 Cost: -0.42443208372223995 Weight: 0.3951424\n",
      "Iteration: 7 Cost: -0.49130488558223373 Weight: 0.41611392\n",
      "Iteration: 8 Cost: -0.5441698083726296 Weight: 0.432891136\n",
      "Iteration: 9 Cost: -0.586056422638483 Weight: 0.4463129088\n",
      "Iteration: 10 Cost: -0.6193063067126292 Weight: 0.45705032704000004\n",
      "Iteration: 11 Cost: -0.6457401932752826 Weight: 0.465640261632\n",
      "Iteration: 12 Cost: -0.666781049279541 Weight: 0.4725122093056\n",
      "Iteration: 13 Cost: -0.683545732005594 Weight: 0.47800976744448\n",
      "Iteration: 14 Cost: -0.6969139568569305 Weight: 0.48240781395558396\n",
      "Iteration: 15 Cost: -0.7075806830871159 Weight: 0.4859262511644672\n",
      "Iteration: 16 Cost: -0.7160962377346984 Weight: 0.48874100093157374\n",
      "Iteration: 17 Cost: -0.7228972725973624 Weight: 0.490992800745259\n",
      "Iteration: 18 Cost: -0.7283307988200363 Weight: 0.4927942405962072\n",
      "Iteration: 19 Cost: -0.7326729467310027 Weight: 0.49423539247696574\n",
      "Iteration: 20 Cost: -0.7361436742967851 Weight: 0.49538831398157257\n",
      "Iteration: 21 Cost: -0.7389183422610974 Weight: 0.4963106511852581\n",
      "Iteration: 22 Cost: -0.7411368516160262 Weight: 0.49704852094820645\n",
      "Iteration: 23 Cost: -0.7429108750893958 Weight: 0.49763881675856514\n",
      "Iteration: 24 Cost: -0.7443295921013247 Weight: 0.49811105340685213\n",
      "Iteration: 25 Cost: -0.7454642445801367 Weight: 0.4984888427254817\n",
      "Iteration: 26 Cost: -0.7463717610395189 Weight: 0.4987910741803854\n",
      "Iteration: 27 Cost: -0.747097642671877 Weight: 0.4990328593443083\n",
      "Iteration: 28 Cost: -0.7476782637952692 Weight: 0.4992262874754466\n",
      "Iteration: 29 Cost: -0.7481427068171866 Weight: 0.49938102998035727\n",
      "Iteration: 30 Cost: -0.7485142267535709 Weight: 0.4995048239842858\n",
      "Iteration: 31 Cost: -0.7488114206347427 Weight: 0.49960385918742867\n",
      "Iteration: 32 Cost: -0.7490491616162009 Weight: 0.49968308734994293\n",
      "Iteration: 33 Cost: -0.7492393453623414 Weight: 0.49974646987995436\n",
      "Iteration: 34 Cost: -0.7493914865742766 Weight: 0.4997971759039635\n",
      "Iteration: 35 Cost: -0.7495131958414394 Weight: 0.4998377407231708\n",
      "Iteration: 36 Cost: -0.7496105608856432 Weight: 0.4998701925785366\n",
      "Iteration: 37 Cost: -0.7496884514045092 Weight: 0.4998961540628293\n",
      "Iteration: 38 Cost: -0.7497507628490441 Weight: 0.49991692325026343\n",
      "Iteration: 39 Cost: -0.7498006113835145 Weight: 0.4999335386002107\n",
      "Iteration: 40 Cost: -0.7498404898135504 Weight: 0.49994683088016856\n",
      "Iteration: 41 Cost: -0.7498723923031532 Weight: 0.4999574647041348\n",
      "Iteration: 42 Cost: -0.7498979141320028 Weight: 0.49996597176330787\n",
      "Iteration: 43 Cost: -0.7499183314908695 Weight: 0.4999727774106463\n",
      "Iteration: 44 Cost: -0.7499346653112666 Weight: 0.49997822192851704\n",
      "Iteration: 45 Cost: -0.7499477323248989 Weight: 0.4999825775428136\n",
      "Iteration: 46 Cost: -0.7499581859084858 Weight: 0.4999860620342509\n",
      "Iteration: 47 Cost: -0.7499665487578713 Weight: 0.4999888496274007\n",
      "Iteration: 48 Cost: -0.74997323902619 Weight: 0.4999910797019206\n",
      "Iteration: 49 Cost: -0.7499785912336834 Weight: 0.49999286376153645\n",
      "Iteration: 50 Cost: -0.7499828729950948 Weight: 0.49999429100922915\n",
      "Iteration: 51 Cost: -0.7499862984012908 Weight: 0.49999543280738334\n",
      "Iteration: 52 Cost: -0.7499890387243702 Weight: 0.49999634624590666\n",
      "Iteration: 53 Cost: -0.7499912309816321 Weight: 0.49999707699672535\n",
      "Iteration: 54 Cost: -0.7499929847866729 Weight: 0.4999976615973803\n",
      "Iteration: 55 Cost: -0.7499943878302131 Weight: 0.4999981292779042\n",
      "Iteration: 56 Cost: -0.7499955102647304 Weight: 0.4999985034223234\n",
      "Iteration: 57 Cost: -0.7499964082121426 Weight: 0.4999988027378587\n",
      "Iteration: 58 Cost: -0.7499971265699434 Weight: 0.49999904219028696\n",
      "Iteration: 59 Cost: -0.7499977012561014 Weight: 0.49999923375222954\n",
      "Iteration: 60 Cost: -0.7499981610049753 Weight: 0.49999938700178365\n",
      "Iteration: 61 Cost: -0.7499985288040403 Weight: 0.4999995096014269\n",
      "Iteration: 62 Cost: -0.7499988230432708 Weight: 0.49999960768114154\n",
      "Iteration: 63 Cost: -0.7499990584346412 Weight: 0.49999968614491325\n",
      "Iteration: 64 Cost: -0.7499992467477288 Weight: 0.4999997489159306\n",
      "Iteration: 65 Cost: -0.7499993973981929 Weight: 0.49999979913274445\n",
      "Iteration: 66 Cost: -0.7499995179185608 Weight: 0.49999983930619557\n",
      "Iteration: 67 Cost: -0.7499996143348528 Weight: 0.49999987144495645\n",
      "Iteration: 68 Cost: -0.7499996914678848 Weight: 0.49999989715596516\n",
      "Iteration: 69 Cost: -0.7499997531743097 Weight: 0.49999991772477215\n",
      "Iteration: 70 Cost: -0.7499998025394488 Weight: 0.4999999341798177\n",
      "Iteration: 71 Cost: -0.7499998420315597 Weight: 0.49999994734385417\n",
      "Iteration: 72 Cost: -0.7499998736252482 Weight: 0.49999995787508333\n",
      "Iteration: 73 Cost: -0.7499998989001988 Weight: 0.49999996630006666\n",
      "Iteration: 74 Cost: -0.7499999191201594 Weight: 0.49999997304005334\n",
      "Iteration: 75 Cost: -0.7499999352961275 Weight: 0.4999999784320427\n",
      "Iteration: 76 Cost: -0.7499999482369022 Weight: 0.4999999827456342\n",
      "Iteration: 77 Cost: -0.7499999585895218 Weight: 0.4999999861965073\n",
      "Iteration: 78 Cost: -0.7499999668716175 Weight: 0.4999999889572059\n",
      "Iteration: 79 Cost: -0.749999973497294 Weight: 0.4999999911657647\n",
      "Iteration: 80 Cost: -0.7499999787978353 Weight: 0.49999999293261177\n",
      "Iteration: 81 Cost: -0.7499999830382682 Weight: 0.49999999434608944\n",
      "Iteration: 82 Cost: -0.7499999864306146 Weight: 0.4999999954768716\n",
      "Iteration: 83 Cost: -0.749999989144492 Weight: 0.4999999963814973\n",
      "Iteration: 84 Cost: -0.7499999913155935 Weight: 0.4999999971051978\n",
      "Iteration: 85 Cost: -0.7499999930524748 Weight: 0.49999999768415826\n",
      "Iteration: 86 Cost: -0.7499999944419797 Weight: 0.4999999981473266\n",
      "Iteration: 87 Cost: -0.7499999955535839 Weight: 0.49999999851786125\n",
      "Iteration: 88 Cost: -0.7499999964428672 Weight: 0.499999998814289\n",
      "Iteration: 89 Cost: -0.7499999971542937 Weight: 0.4999999990514312\n",
      "Iteration: 90 Cost: -0.7499999977234348 Weight: 0.49999999924114497\n",
      "Iteration: 91 Cost: -0.749999998178748 Weight: 0.49999999939291595\n",
      "Iteration: 92 Cost: -0.7499999985429984 Weight: 0.49999999951433277\n",
      "Iteration: 93 Cost: -0.7499999988343986 Weight: 0.49999999961146624\n",
      "Iteration: 94 Cost: -0.7499999990675188 Weight: 0.49999999968917297\n",
      "Iteration: 95 Cost: -0.749999999254015 Weight: 0.49999999975133835\n",
      "Iteration: 96 Cost: -0.749999999403212 Weight: 0.4999999998010707\n",
      "Iteration: 97 Cost: -0.7499999995225695 Weight: 0.4999999998408565\n",
      "Iteration: 98 Cost: -0.7499999996180557 Weight: 0.49999999987268523\n",
      "Iteration: 99 Cost: -0.7499999996944446 Weight: 0.4999999998981482\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the quadratic function\n",
    "def f(x):\n",
    "    return x**2 - 4*x + 1\n",
    "\n",
    "# Define the derivative of the quadratic function\n",
    "def f_prime(x):\n",
    "    return 2*x - 1\n",
    "\n",
    "# Gradient descent function to minimize f(x) with cost and weight tracking\n",
    "def gradient_descent(starting_point, learning_rate=0.1, n_iterations=100):\n",
    "    x = starting_point\n",
    "    cost_history = []\n",
    "    weight_history = []\n",
    "    \n",
    "    for _ in range(n_iterations):\n",
    "        gradient = f_prime(x)\n",
    "        x -= learning_rate * gradient\n",
    "        \n",
    "        # Calculate and store cost\n",
    "        cost = f(x)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        # Store weights\n",
    "        weight_history.append(x)\n",
    "    \n",
    "    return x, cost_history, weight_history\n",
    "\n",
    "# Perform gradient descent to minimize f(x)\n",
    "starting_point = 0  # Starting point for gradient descent\n",
    "minimizer, cost_history, weight_history = gradient_descent(starting_point)\n",
    "\n",
    "# Print minimum value of x\n",
    "print(\"Minimum value of x:\", minimizer)\n",
    "\n",
    "# Print cost and weight values at every point\n",
    "for i in range(len(cost_history)):\n",
    "    print(\"Iteration:\", i, \"Cost:\", cost_history[i], \"Weight:\", weight_history[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bc50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
